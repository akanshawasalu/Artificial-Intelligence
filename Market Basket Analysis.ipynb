{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Market Bascket Analysis Using Apriori Algorithm</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Prepare the Data</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data need to be processed to generate records and item-list.<br>\n",
    "Consider minimum_support_count to be 2.<br>\n",
    "Pandas library is used to import the CSV file.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Item1   Item2       Item3       Item4\n",
      "0     MILK   BREAD     BISCUIT         NaN\n",
      "1    BREAD    MILK     BISCUIT  CORNFLAKES\n",
      "2    BREAD     TEA   BOURNVITA         NaN\n",
      "3      JAM   MAGGI       BREAD        MILK\n",
      "4    MAGGI     TEA     BISCUIT         NaN\n",
      "5    BREAD     TEA   BOURNVITA         NaN\n",
      "6    MAGGI     TEA  CORNFLAKES         NaN\n",
      "7    MAGGI   BREAD         TEA     BISCUIT\n",
      "8      JAM   MAGGI       BREAD         TEA\n",
      "9    BREAD    MILK         NaN         NaN\n",
      "10  COFFEE    COCK     BISCUIT  CORNFLAKES\n",
      "11  COFFEE    COCK     BISCUIT  CORNFLAKES\n",
      "12  COFFEE   SUGER   BOURNVITA         NaN\n",
      "13   BREAD  COFFEE        COCK         NaN\n",
      "14   BREAD   SUGER     BISCUIT         NaN\n",
      "15  COFFEE   SUGER  CORNFLAKES         NaN\n",
      "16   BREAD   SUGER   BOURNVITA         NaN\n",
      "17   BREAD  COFFEE       SUGER         NaN\n",
      "18   BREAD  COFFEE       SUGER         NaN\n",
      "19     TEA    MILK      COFFEE  CORNFLAKES\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "data = pd.read_csv('Book1.csv')\n",
    "\n",
    "minimum_support_count = 2\n",
    "records = []\n",
    "for i in range(0, 19):\n",
    "    records.append([str(data.values[i,j]) for j in range(0, 4)])\n",
    "\n",
    "items = sorted([item for sublist in records for item in sublist if item != 'nan'])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 1 -</h3><br>The candidate_set C1 is generated by measuring the support_count of each item in the dataset. Item_set L1 is generated by comparing C1 support_count with minimum_support_count. Here k=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_1(items, minimum_support_count):\n",
    "    c1 = {i:items.count(i) for i in items}\n",
    "    l1 = {}\n",
    "    for key, value in c1.items():\n",
    "        if value >= minimum_support_count:\n",
    "           l1[key] = value \n",
    "    \n",
    "    return c1, l1\n",
    "c1,l1 = stage_1(items, minimum_support_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 2 -</h3>\n",
    "\n",
    "In this stage, candidate_set C2 is generated using Item_set L1 from the previous step.<br>Check all subsets in itemset are frequent if not, remove respective itemset from the list.<br>Item_set L2 is generated by comparing candidate_set C2 with minimum_support_count.<br>Here k=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_subset_frequency(itemset, l, n):\n",
    "    if n>1:    \n",
    "        subsets = list(itertools.combinations(itemset, n))\n",
    "    else:\n",
    "        subsets = itemset\n",
    "    for iter1 in subsets:\n",
    "        if not iter1 in l:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sublist(l1,l2):\n",
    "    flag=0\n",
    "    f=1\n",
    "    for x in l1:\n",
    "        if (x in l2):\n",
    "            flag = flag+1\n",
    "        else:\n",
    "            f=0;\n",
    "            break;\n",
    "    if(f == 1):\n",
    "        return True\n",
    "    if(f == 0):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_2(l1, records, minimum_support_count):\n",
    "    l1 = sorted(list(l1.keys()))\n",
    "    L1 = list(itertools.combinations(l1, 2))\n",
    "    c2 = {}\n",
    "    l2 = {}\n",
    "    for iter1 in L1:\n",
    "        count = 0\n",
    "        for iter2 in records:\n",
    "            if sublist(iter1, iter2):\n",
    "                count+=1\n",
    "        c2[iter1] = count\n",
    "    for key, value in c2.items():\n",
    "        if value >= minimum_support_count:\n",
    "            if check_subset_frequency(key, l1, 1):\n",
    "                l2[key] = value \n",
    "    \n",
    "    return c2, l2\n",
    "c2,l2 = stage_2(l1, records, minimum_support_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check subsets of an itemset are frequent, we should pass current stage itemset, the previous stage itemset, in this case, L1, and k-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step — 3\n",
    "\n",
    "In this stage, candidate_set C3 is generated using Item_set L2 from the previous step.<br>Check all subsets in itemset are frequent if not, remove respective itemset from the list.<br>Item_set L3 is generated by comparing candidate_set C3 with minimum_support_count.<br>Here k=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "l3 =  {('BISCUIT', 'BREAD', 'MILK'): 2, ('BISCUIT', 'COCK', 'COFFEE'): 2, ('BISCUIT', 'COCK', 'CORNFLAKES'): 2, ('BISCUIT', 'COFFEE', 'CORNFLAKES'): 2, ('BISCUIT', 'MAGGI', 'TEA'): 2, ('BOURNVITA', 'BREAD', 'TEA'): 2, ('BREAD', 'COFFEE', 'SUGER'): 2, ('BREAD', 'JAM', 'MAGGI'): 2, ('BREAD', 'MAGGI', 'TEA'): 2, ('COCK', 'COFFEE', 'CORNFLAKES'): 2}\n"
     ]
    }
   ],
   "source": [
    "def stage_3(l2, records, minimum_support_count):\n",
    "    l2 = list(l2.keys())\n",
    "    L2 = sorted(list(set([item for t in l2 for item in t])))\n",
    "    L2 = list(itertools.combinations(L2, 3))\n",
    "    c3 = {}\n",
    "    l3 = {}\n",
    "    for iter1 in L2:\n",
    "        count = 0\n",
    "        for iter2 in records:\n",
    "            if sublist(iter1, iter2):\n",
    "                count+=1\n",
    "        c3[iter1] = count\n",
    "    for key, value in c3.items():\n",
    "        if value >= minimum_support_count:\n",
    "            if check_subset_frequency(key, l2, 2):\n",
    "                l3[key] = value \n",
    "        \n",
    "    return c3, l3\n",
    "c3,l3 = stage_3(l2, records, minimum_support_count)\n",
    "#print(\"\\nl3 = \",l3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step — 4</h3>\n",
    "\n",
    "In this stage, candidate_set C4 is generated using Item_set L3 from the previous step.<br>Check all subsets in itemset are frequent if not, remove respective itemset from the list.<br>Item_set L4 is generated by comparing candidate_set C4 with minimum_support_count.<br>Here k=4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_4(l3, records, minimum_support_count):\n",
    "    l3 = list(l3.keys())\n",
    "    L3 = sorted(list(set([item for t in l3 for item in t])))\n",
    "    L3 = list(itertools.combinations(L3, 4))\n",
    "    c4 = {}\n",
    "    l4 = {}\n",
    "    for iter1 in L3:\n",
    "        count = 0\n",
    "        for iter2 in records:\n",
    "            if sublist(iter1, iter2):\n",
    "                count+=1\n",
    "        c4[iter1] = count\n",
    "    for key, value in c4.items():\n",
    "        if value >= minimum_support_count:\n",
    "            if check_subset_frequency(key, l3, 3):\n",
    "                l4[key] = value \n",
    "        \n",
    "    return c4, l4\n",
    "c4,l4 = stage_4(l3, records, minimum_support_count)\n",
    "#print(\"c4 = \",c4)\n",
    "#print(\"\\nl4 = \",l4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can stop here because no frequent subsets are found further.\n",
    "Generate the association rule\n",
    "\n",
    "To generate association rule for the dataset, we need to calculate the confidence of each rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nConfidence:Confidence(A->B)=Support_count(A∪B)/Support_count(A)\\nConfidence((COCK, COFFEE)->CORNFLAKES) = \\n    Support_count(‘COCK’, ‘COFFEE’, ‘CORNFLAKES’)/Support_count(‘COCK’, ‘COFFEE’)'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Rule generation of itemset '''\n",
    "'''\n",
    "Confidence:Confidence(A->B)=Support_count(A∪B)/Support_count(A)\n",
    "Confidence((COCK, COFFEE)->CORNFLAKES) = \n",
    "    Support_count(‘COCK’, ‘COFFEE’, ‘CORNFLAKES’)/Support_count(‘COCK’, ‘COFFEE’)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = []\n",
    "for iter1 in list(l3.keys()):\n",
    "    subsets = list(itertools.combinations(iter1, 2))\n",
    "    sets.append(subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing association rule on generated set from L3<br>Minimum confidence is assumed to be 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_count(itemset, l1,l2,l3):\n",
    "    if(len(itemset) == 1):\n",
    "        return l1[itemset]\n",
    "    if(len(itemset) == 2):\n",
    "        return l2[itemset]\n",
    "    if(len(itemset) == 3):\n",
    "        return l3[itemset]\n",
    "confi = {}\n",
    "sorted_confi = {}\n",
    "list_l3 = list(l3.keys())\n",
    "for i in range(0, len(list_l3)):\n",
    "    for iter1 in sets[i]:\n",
    "        a = iter1\n",
    "        b = set(list_l3[i]) - set(iter1)\n",
    "        confidence = (support_count(list_l3[i], l1,l2,l3)/support_count(iter1, l1,l2,l3))*100\n",
    "        x = str(a) + '->' + str(b)\n",
    "        confi[x] = confidence\n",
    "        if(confidence > 50):\n",
    "            sorted_confi[x] = confidence\n",
    "#print(\"\\n\\nconfi = \",confi)\n",
    "#print(\"\\n\\nsorted_confi = \",sorted_confi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ('BISCUIT', 'MILK')->{'BREAD'}  :  100.0\n",
      "\n",
      " ('BISCUIT', 'COCK')->{'COFFEE'}  :  100.0\n",
      "\n",
      " ('BISCUIT', 'COFFEE')->{'COCK'}  :  100.0\n",
      "\n",
      " ('COCK', 'COFFEE')->{'BISCUIT'}  :  66.66666666666666\n",
      "\n",
      " ('BISCUIT', 'COCK')->{'CORNFLAKES'}  :  100.0\n",
      "\n",
      " ('BISCUIT', 'CORNFLAKES')->{'COCK'}  :  66.66666666666666\n",
      "\n",
      " ('COCK', 'CORNFLAKES')->{'BISCUIT'}  :  100.0\n",
      "\n",
      " ('BISCUIT', 'COFFEE')->{'CORNFLAKES'}  :  100.0\n",
      "\n",
      " ('BISCUIT', 'CORNFLAKES')->{'COFFEE'}  :  66.66666666666666\n",
      "\n",
      " ('COFFEE', 'CORNFLAKES')->{'BISCUIT'}  :  66.66666666666666\n",
      "\n",
      " ('BISCUIT', 'MAGGI')->{'TEA'}  :  100.0\n",
      "\n",
      " ('BISCUIT', 'TEA')->{'MAGGI'}  :  100.0\n",
      "\n",
      " ('BOURNVITA', 'BREAD')->{'TEA'}  :  66.66666666666666\n",
      "\n",
      " ('BOURNVITA', 'TEA')->{'BREAD'}  :  100.0\n",
      "\n",
      " ('BREAD', 'COFFEE')->{'SUGER'}  :  66.66666666666666\n",
      "\n",
      " ('BREAD', 'JAM')->{'MAGGI'}  :  100.0\n",
      "\n",
      " ('BREAD', 'MAGGI')->{'JAM'}  :  66.66666666666666\n",
      "\n",
      " ('JAM', 'MAGGI')->{'BREAD'}  :  100.0\n",
      "\n",
      " ('BREAD', 'MAGGI')->{'TEA'}  :  66.66666666666666\n",
      "\n",
      " ('COCK', 'COFFEE')->{'CORNFLAKES'}  :  66.66666666666666\n",
      "\n",
      " ('COCK', 'CORNFLAKES')->{'COFFEE'}  :  100.0\n",
      "\n",
      " ('COFFEE', 'CORNFLAKES')->{'COCK'}  :  66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "def print_final():\n",
    "    for s in sorted_confi:\n",
    "        print(\"\\n\",s,\" : \",sorted_confi[s])\n",
    "print(\"Final Result\")\n",
    "print_final()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3>\n",
    "<h3>We have successfully implemented Apriori Algorithm in Python for Market Basket Analysis</h3><br>\n",
    "This association rule mining technique was implemented by giants like Amazon, Netflix, Google, Flipkart, and Spotify in their recommendation platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
